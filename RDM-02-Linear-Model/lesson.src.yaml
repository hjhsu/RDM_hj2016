- Class: meta
  Course: RDataMining_HJ
  Lesson: RDM-02-Supervised-Learning-01-Linear-Model
  Author: Wush Wu & Hwai-Jung Hsu
  Type: Standard
  Organization: Taiwan R User Group
  Version: 2.3.1.2

- Class: text
  Output: |
    這個課程跟同學介紹如何用R自資料中建立線性模型、學習參數與做預測和選模。

- Class: text
  Output: |
    在R中要建立線性模型，首先要把資料給整理好。舉例來說，先把資料整理成data.frame是很常見的作法。

- Class: cmd_question
  Output: |
    我們要練習的資料集是iris，請同學輸入data(iris)從套件載入該資料集。
  CorrectAnswer: data(iris)

- Class: cmd_question
  Output: |
    請同學輸入`?iris`看看資料的背景

- Class: text
  Output: |
    我們要利用iris中的其他資料，來預測Sepal.Length欄位的值

- Class: cmd_question
  Output: |
    iris是一個data.frame。請同學輸入：`sapply(iris, class)`看一看每個欄位的型態

- Class: mult_question
  Output: |
    請問唯一屬於類別型變數的欄位名稱是？請輸入字串
  AnswerChoices: Sepal.Length;Sepal.Width;Petal.Length;Petal.Width;Species
  CorrectAnswer: "Species"
  AnswerTests: omnitest(correctVal = "Species")

- Class: text
  Output: |
    因為Sepal.Length是數值型變數，所以我們可以使用建立線性模型的函數`lm`做學習，請同學輸入：`?lm`看看建立線性模型的說明文件。

- Class: text
  Output: |
    `lm`的第一個參數是`formula`，是R 中常常用來描述數據間關係的語法。
    `data`代表的是R 要取得資料的data.frame。

- Class: cmd_question
  Output: |
    使用formula時，如果輸入： `xxx ~ .`就代表xxx是目標變數，而其他欄位通通都當成解釋變數。
    請同學輸入：`m.iris1 <- lm(Sepal.Length ~ ., iris)`
  CorrectAnswer: m.iris1 <- lm(Sepal.Length ~ ., iris)

- Class: cmd_question
  Output: |
    請用`coef(m.iris1)`列出所有學到的模型參數。

- Class: cmd_question
  Output: |
    我們想要比較`coef(m.iris1)`是不是大部分都屬於iris的欄位名稱。
    請同學先輸入：`tmp1 <- names(coef(m.iris1))`
  CorrectAnswer: tmp1 <- names(coef(m.iris1))

- Class: cmd_question
  Output: |
    接著請同學輸入：`tmp2 <- colnames(iris)`取得iris的欄位名稱。

- Class: cmd_question
  Output: |
    最後我們運用`setdiff`（集合的減法）來找出`tmp1`中不屬於`tmp2`的元素。請同學輸入：
    `setdiff(tmp1, tmp2)`
  CorrectAnswer: setdiff(tmp1, tmp2)

- Class: text
  Output: |
    除了(Intercept)之外，同學應該還會看到Speciesversicolor與Speciesvirginica。
    這是因為Species是類別型變數，所以R 把欄位名稱與類別名稱接在一起當成參數名稱。
    另外考量到解釋性，Speciessetosa（欄位名稱+第一個類別名稱）會被移除，只留下
    剩下的兩個類別。

- Class: text
  Output: |
    線性模型處理類別型變數的概念，很接近「分組取平均」。
    
- Class: script
  Output: |
    為了驗證這個概念，我們就iris資料集中不同種類的花，分別計算其Sepal.Length的平均。
  Script: ml-01-01.R
  AnswerTests: ml_01_01()
  
- Class: cmd_question
  Output: |
    為了方便比較，請同學輸入：`answer_01`把上一題的答案輸出到console上

- Class: cmd_question
  Output: |
    接著請同學輸入：`lm(Sepal.Length ~ Species, iris)`，看看學習出來的結果。

- Class: text
  Output: |
    模型中的參數(Intercept)，其實就是setosa中Sepal.Length的平均值；
    模型中的參數Speciesversicolor則是versicolor與setosa的Sepal.Length之平均值的差；
    Speciesvirginica同理。

- Class: cmd_question
  Output: |
    我們也可以透過適當的設定formula來讓模型更複雜。請同學輸入：
    `m.iris2 <- lm(Sepal.Length ~ .^2, iris)`這種作法除了考量到各種欄位
    對Sepal.Length的個別影響之外，欄位的影響力也會受到其它欄位的影響。

- Class: cmd_question
  Output: |
    請同學輸入`m.iris2`看看這個模型的參數

- Class: text
  Output: |
    除了原本在m.iris1看到的參數之外，還多了許多中間有`:`的參數。舉例來說，Sepal.Width:Petal.Width
    代表的是Sepal.Width與Petal.Width對Sepal.Length（目標變數）的影響力，會受到彼此的影響。
    Sepal.Width:Petal.Width 這個參數，在統計上稱為：Sepal.Width與Petal.Width的「交互作用」。或是
    「二次交互作用項」。因為這類的交互作用，是可以擴充到三、甚至四個變數的狀況。
    

- Class: text
  Output: |
    在formula中的`Sepal.Length ~ .^2`中，`.`就代表除了Sepal.Length之外所有在iris中的欄位。而`^2`
    則代表所有這些欄位之間的兩兩組合（二次交互作用項），都要放到模型之中。同理，`^3`就代表所有的
    三次交互作用項。我們也可以手動指定要放入模型的交互作用，
    例如：`Sepal.Length ~ . + Sepal.Width:Petal.Width`就代表除了`m.iris1`的參數之外，我們只增加了
    `Sepal.Width:Petal.Width`這一個二次交互作用項。

- Class: text
  Output: |
    我們可以一直放高次的交互作用到模型之中，讓模型變得非常複雜。
    結果導致我們能夠計算出很多個模型，但是哪一個才是「最好用」的模型呢？

- Class: cmd_question
  Output: |
    我們可以用指令`residuals(m.iris1)`來看到「實際的Sepal.Length」與「m.iris1預測的Sepal.Length」
    的差距。這些在training dataset上看到的模型與實際觀測值之間的差距，稱為residuals。
    請同學試試看這個指令

- Class: cmd_question
  Output: |
    透過比較residuals的大小，我們可以知道模型在training dataset描述Sepal.Length的變化上，做的好不好。
    請輸入：`sum(residuals(m.iris1)^2)`，計算residuals的平方和
    
- Class: cmd_question
  Output: |
    請輸入：`sum(residuals(m.iris2)^2)`，計算第二個模型的residuals的平方和
    
- Class: mult_question
  Output: |
    請問哪一個模型的residuals的平方和比較小？描述training dataset的變化描述的比較好？
  AnswerChoices: m.iris1;m.iris2
  CorrectAnswer: "m.iris2"
  AnswerTests: omnitest(correctVal = "m.iris2")

- Class: text
  Output: |
    事實上，模型越複雜，training dataset上的Residuals的平方和就越小。

- Class: script
  Output: |
    請同學計算一個有所有三次交互作用項的模型，residuals的平方和為多少。同學可以
    藉此機會確認，這個模型的residual的平方和，會小於`m.iris2`的residuals的平方和。
  Script: ml-01-02.R
  AnswerTests: ml_01_02()

- Class: cmd_question
  Output: |
    事實上，透過residuals的平方和，我們可以計算出R Squared。R Squared是很多統計學課程中
    會提到的「描述線性模型表現」的指標（我們略過嚴謹的數學定義）。數學上可以證明，R Squared
    的值會介於0與1之間。0代表模型完全沒有解釋到目標變數在training dataset上的變化；1代表模型
    100%解釋了目標變數在training dataset的行為（同時也代表residuals都是0）。R Squared等價於
    「相關係數的平方」。請同學輸入`summary(m.iris2)`，這個詳細的表格會回報模型的R Squared。

- Class: text
  Output: |
    關於R Squared的算法，各位可以參考https://en.wikipedia.org/wiki/Coefficient_of_determination
    
- Class: text
  Output: |
    實務上，R Squared並不代表模型比較「好用」（例如：預測的比較準）。
    模型在training dataset上的表現，「不代表」模型在training dataset以外的資料上
    會表現的比較好。
    透過方法挑選出在training dataset以外的資料上比較好的模型，稱為「選模」。

- Class: cmd_question
  Output: |
    統計學提供了一些統計指標，在只使用training dataset的狀況下，去預測模型在
    在training dataset以外的資料上的表現。R 則有提供相關的實作，甚至連選模的
    過程都實作了。同學可以試試看：`m.iris <- step(m.iris2, steps = 1)`

- Class: text
  Output: |
    R 會去計算AIC(The Akaike information criterion)來評估模型在testing dataset的好壞。
    AIC越小，模型就越好。接著R 會嘗試去拿掉一個欄位、 交互作用項或是新增一個欄位、交互作用項，
    看看模型的AIC會不會提昇。我們可以看到，當拿掉：`Sepal.Width:Species`時，AIC會變低（原本的AIC，
    即是<none>所對應的那一列），而且是這一系列嘗試中，AIC最低的。所以R 就會將`m.iris2`的解釋變數
    組合，從「所有的二次交互作用」(`.^2`)變成「所有的二次交互作用扣除Sepal.Width:Species」
    (`.^2 - Sepal.Width:Species`)。

- Class: cmd_question
  Output: |
    `m.iris <- step(m.iris2)`則會一直重複上述的動作，直到模型的AIC不會變得更低。並把結果的模型
    輸出（寫入變數m.iris）。請同學試試看。

- Class: script
  Output: |
    最後我們請同學利用另一個資料做練習。
  Script: ml-01-03.R
  AnswerTests: ml_01_03()
